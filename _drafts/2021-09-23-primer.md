---
layout: post
title:  "A Machine Learning Primer"
author: seri
categories: [ computer vision ]
image: assets/images/depth/1.jpg
tags: featured
---

<!--more-->

<h2> Fundamentals of Linear Regression </h2>

In this section, we investigate one of the most common and widely used machine learning techniques: <span class="arrow-highlight"> linear regression </span>.

Linear regression is a very intuitive supervised learning algorithm and as its name suggests, it is a <span class="gradient"> regression technique </span>. This means it is used when we have <u> labels that are continuous values </u> such as car prices or the temperature in a room. Furthermore, as its name also suggests, <b> linear regression seeks to find fits of data that are lines </b>. What does this mean?

<h3> Motivations </h3>
Imagine that you received a dataset consisting of cars, where for each car you had the number of miles a car had driven along with its price. In this case, let's assume that you are trying to train a machine learning system that takes in the information about each car, namely the number of miles driven along with its associated price.

Here, for a given car, the miles driven is the input and the price is the output. This data could be represented as $(X,Y)$ coordinates.

In this case, it seems that there is a <span class="shadow"> linear relationship </span> between the miles driven and the price. We could describe the model for our car price dataset as a mathematical function of the form:

$$
F(X) = A_1 \cdot X + A_0
$$

Here, $A_1$ and $A_0$ are called <span class="shadow-blue"> weights </span> and these are values that determine how our linear function behaves on different inputs. All supervised learning algorithms have some set of weights that determine how the algorithm behaves on different inputs, and <u> determining the right weights </u> is really at the core of what we call <span class="shadow-white"> learning </span>.

<h3> A Training Paradigm </h3>
These varieties of linear fits raise the question: how do we actually <u> learn the weights of this model </u> or any machine learning model in general? In particular, how can we leverage the fact that <b> we have the correct labels for the cars </b> in our dataset?

Training and evaluating a machine learning model involves using something called a <span class="glow"> cost function </span>. In the case of supervised learning, a cost function is a measure of how much the <span class="neon"> predicted labels </span> outputted by our model deviate from the <span class="neon-pink"> true labels </span>. Ideally we would like the deviation between the two to be small, and so we want to <span class="highlight-skew"> minimize the value of our cost function </span>. 

A common cost function used for evaluating linear regression models is called the <span class="showup"> least-squares cost function </span>. 

Let's say that we have $n$ datapoints in our dataset. This could look like $[(X_1, Y_1), (X_2, Y_2), \dots, (X_n, Y_n)]$. If we are learning a function like $F(X)$, the least-squares regression model seeks to minimize:

$$
C(X) = \frac{1}{2} \cdot \sum_{i=1}^n (F(X_i) - Y_i)^2
$$

The deviation between our predicted output ($F(X)$) and the true output $Y$ is defined as a <span class="shine"> residual </span>. The least-squares cost is trying to minimize the sum of the squares of the residuals (multiplied by a constant in this case).

Here, it is important to note that $F(X)$ is a function of the weights of our model. In our motivating example, $F(X)$ would be a function of $A_1$ and $A_0$. The values of $A_1$ and $A_0$ that produce our optimal model are the values <u> which achieve teh minimal value of $C(X)$ </u>.





<h2> References </h2>
<ul><li><a=href=""> TheAILearner </a></li>
</ul>

