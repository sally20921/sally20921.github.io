---
layout: post
title:  "A Machine Learning Primer"
author: seri
categories: [ machine learning ]
image: assets/images/depth/1.jpg
tags: featured
---

<!--more-->

<h2> Fundamentals of Linear Regression </h2> 

In this section, we investigate one of the most common and widely used machine learning techniques: linear regression.

Linear regression is a very intuitive supervised learning algorithm and as its name suggests, it is a regression technique. This means that is is used <span class="underline"> when we have labels that are continuous values </span> such as car prices or the temperature in a room. 

Linear regression seeks to find fits of data that are lines. What does this mean?

<h3> Motivations </h3>

Imagine that you received a dataset consisting of cars, where for each car you had the number of miles a car had driven along with its price. In this case, let's assume that you are trying to train a machine learning system that takes in the information about each car, namely the number of miles driven along with its associated price. 

Here for a given car, the miles driven is the input and the price is the output. This data could be represented as $(X,Y)$ coordinates. 

It seems that there is a linear relationship between the miles driven and the price. We could describe the model for our car price dataset as a mathematical function of the form: $F(X) = A_1 \cdot X + A_0$.

Here, $A_1$ and $A_0$ are called weights and these are the values that determine how our linear function behaves on different inputs. All supervised learning algorithms have some set of weights that determine how the algorithm behaves on different inputs, and determining the right weights is really at the core of what we call <span class="blue"> learning </span>.

<h3> A Training Paradigm </h3>

How do we actually learn the weights of this model or any machine learning model in general? In particular, how can we leverage the fact that we have the correct labels for the cars in our dataset?

Training and evaluating machine learning model involves using something called a <span class="red"> cost function </span>. In the case of supervised learning, a cost function is a measure of how much the predicted labels outputted by our model deviate from the true labels. Ideally, we would like the deviation between the two to be small, and so we want to minimize the value of our cost function.

A common cost function used for evaluating linear regression models is called the <span class="blue"> least-squares cost function </span>. Let's say that we have $n$ datapoints in our dataset.

This could look like $[(X_1, Y_1), (X_2, Y_2), \dots, (X_n, Y_n)]$. If we are learning a function $F(X)$, the least-squares regression model seeks to minimize: 

$$
C(X) = \frac{1}{2} \cdot \sum_{i=1}^n (F(X_i) - Y_i)^2
$$

The deviation between our predicted output ($F(X)$) and the true output ($Y$) is defined as a residual. The least-squares cost is trying to minimize the sum of the squares of the residuals (multiplied by a constant in this case).

Here it is important to note that $F(X)$ is a function of the weights of our model. In our motivating example, $F(X)$ would be a function of $A_1$ and $A_0$. The values of $A_1$ and $A_0$ that produce our optimal model are the values which achieve the minimal value of $C(X)$. 

How do we actually compute the weights that achieve the minimal values of our cost? Here, as with all machine learning models, we have two options: an analytical or a numerical solution. 

In analytical solution, we seek to find an exact closed-form expression for the optimal value. In this particular case, that involves using standard calculus optimization. We would take the gradients (which are just fancy derivatives) of the cost function with respect to the weights, set those gradients to $0$, and then solve for the weights that achieve the $0$ gradient. 

This technique is nice because once we have computed the closed-form expression for the gradients, we can get the optimal weight values for any new data. Here we are able to develop an analytical solution in the case of linear regression with a least-squares cost function. 

However, not all models have nice well-formed gradient expressions that allow us to solve for the global optimum of a problem. For these problems, we must turn to numerical methods. Numerical methods typically involve a step-wise update procedure that iteratively brings weights closer to their optimal value. Here, we again compute the gradients with respect to all the weights and then apply the following update for each weight $A$:

$$
A_{new} = A_{old} - \alpha \cdot \frac{\partial C}{\partial A}
$$

We continue applying these updates for some number of iterations until our weight values converge, by which I mean to say they don't change too much from one iteration to the next. This very important numerical optimization procedure is called gradient descent. 


Note in our expression for gradient descent above, we have this magical alpha ($\alpha$) value being multiplied to the gradient. $\alpha$ is an example of what is called in machine learning a hyperparameter. The value of this hyperparameter $\alpha$ determines how quickly updates are made to our weights. We are free to adjust the value so that gradient descent converges more quickly.

Many machine learning algorithms have their own hyperparameters that we can adjust and fine-tune to achieve better performance in our algorithm. For some algorithms, such as in deep learning, hyperparameter tuning is a super important task that can drastically impact how good of a system we build. 

In the case of linear regression with a least-squares cost we are guaranteed that gradient descent will eventually converge to the optimal weight values. However, certain optimization problems don't have that guarantee, and the best we can hope for is that gradient descent converges to something close to the global optimum. A prominent example of models with this behavior are deep learning models, which we will discuss in greater depth later.

An important point to keep in mind is that the original linear model we we only have two weights, $A_1$ and $A_0$. But what if we really believed that car prices were a function of two features, the number of miles driven and the size of the trunk space in cubic feet?

Now if we wanted to train a linear regression model, our dataset would have to include the number of miles driven, the size of the trunk space, and the price for every car. We would also now have three weights in our linear regression model: $A_0$, $A_1$ and $A_2$.

Furthermore, our data would now exist in a 3D coordinate system, not a 2D one. However, we could use the same least-squares cost function to optimize our model. As we increase the number of features, the same basic algorithmic considerations apply with a few caveats. We will discuss these caveats when we discuss the bias-variance tradeoff.

<h3> When Does a Linear Line Fit? </h3>

When does linear regression work well as a modelling algorithm choice? In practice, it turns out that linear regression works best when there actually is a linear relationship between the inputs and the outputs of your data. 

When we are building a machine learning system, there are few factors that we have to determine. First off, we need to extract the correct features from our data. This step is crucial!

After selecting features, we need to pick the right modelling algorithm to fit. For example, if we think there is a linear relationship between our inputs and outputs, a linear regression may make sense. However, if we don't think a line makes sense, we would pick a different model that has some different assumptions about the underlying structure of the data. We will investigate many other classes of models with their assumptions about the data in later sections.

<h2> Introduction to Logistic Regression </h2>

In this section, we will continue with our study of supervised learning by exploring our first classification algorithm. A vast majority of problems tackled in the real world involve classification, so we are at an exciting milestone in our study of artificial intelligence!

Ironically, the first classification algorithm we will investigate is called logistic regression. Putting aside name confusion for now, the form of logistic regression we will look at is for binary classification tasks, where we only output two possible labels.

<h3> Model Definition </h3>

To motivate logistic regression, let us begin with a modified version of our running car example from the last section on linear regression. 

Rather than build a system to predict the price of a car, we will build a system that is provided a set of features of a car and will determine whether the car is expensive or cheap. In particular, we will extract a few different features from the cars in our dataset such as the size of the trunk, the number of miles driven, and who the car manufacturer is. 

Let's call these features $X_1$, $X_2$ and $X_3$. We will consolidate these features into a single vector variable $X = (X_1, X_2, X_3)$. These features will be fed into a mathematical function $F(X)$, to get a probability of whether or not the car is expensive. 

In other words, we will compute $F(X)$ (where the function $F$ is unspecified for now), and this will give us a probability between $0$ and $1$. We will then say that if our probability is greater than or equal to 0.5, we will label our prediction, expensive, otherwise, it will be cheap. 

Note that we could have reversed the labels and said a probability greater than 0.5 is cheap and it would not have made a difference. The only important thing is to be consistent once you've selected a labelling scheme!

What exactly is going on in that $F(X)$ function? The logistic regression model describes the relationship between our input car features and the output probabilities through a very particular mathematical formulation. Given our input features $X_1$, $X_2$, and $X_3$ the formulation is as follows:

$$
F(X) = \frac{1}{1+e^{-(A_1 \cdot X_1 + A_2 \cdot X_2 + A_3 \cdot X_3}}
$$

where here the weights of our model that we have to learn are $A_1$, $A_2$, and $A_3$. 

<h3> Training the Model </h3>

How do we train the weights of a logistic regression model? Let's assume that we have a dataset of $n$ cars with their associated true labels: $[(X_1, Y_1), (X_2, Y_2), \dots, (X_n, Y_n)]$. We won't dive into the mathematical details, but it turns out we can write an expression for the total probability of our dataset which looks as follows:

$$
\prod_{i=1}^n (F(X_i))^{Y_i} \cdot (1-F(X_i))^{1-Y_i}
$$

For our purposes, understand that our aim will be to maximize this probability. We can do this by taking the derivative with respect to our weights and setting the derivative to 0. We can then run gradient descent using our computed gradient to get our optimal weights. This is analogous to the procedure used for numerically optimizing a linear regression model in the linear regression section.

<h3> Final Thoughts </h3>

Logistic regression can also be applied to problems with more than just binary outputs for a given set of inputs. In this case, the model is called multinomial logistic regression. 

For this section, we have restricted to binary outputs because it is a natural place to start. That being said, multinomial logistic regression is especially important for more sophisticated models used in deep learning.

When is logistic regression useful? In practice, logistic regression is a very nice off-the-shelf algorithm to begin with when you are doing any type of classification. 

It has a fairly straightforward description, can be trained fairly quickly through techniques such as gradient descent because of its nice derivative, and often works well in practice. It is used frequently in biostatistical applications where there are many binary classification problem. 

<h2> Parametric and Non-Parametric Models </h2>

We will be focusing on probabilistic models of the form $p(y|x)$ or $p(x)$, depending on whether we are interested in supervised or unsupervised learning respectively. There are many ways to define such models, but the most important distinction is this: does the model have a fixed number of parameters, or does the number of parameters grow with the amount of training data?

The former is called a parametric model, and the latter is called a non-parametric model. Parametric models have the advantage of often being faster to use, but the disadvantage of making stronger assumptions about the nature of data distributions. 

Non-parametric models are more flexible, but often computationally intractable for large datasets. We focus on supervised learning for simplicity, although much of our discussion also applies to unsupervised learning. 

<h3> A Simple Non-Parametric Classifier: K-Nearest Neighbors </h3>

A simple example of a non-parametric classifier is the $K$ nearest neighbor (KNN) classifier. This simply looks at the $K$ points in the training set 


<picture><img src="{{site.baseurl}}/assets/images/disparity.png"></picture>

<h2> References </h2>
<ul><li><a=href=""> TheAILearner </a></li>
</ul>

