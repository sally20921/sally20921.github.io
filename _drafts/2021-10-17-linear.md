---
layout: post
title:  "A Machine Learning Primer"
author: seri
categories: [ machine learning ]
image: assets/images/depth/1.jpg
tags: featured
---

<!--more-->

<h2> Fundamentals of Linear Regression </h2> 

In this section, we investigate one of the most common and widely used machine learning techniques: linear regression.

Linear regression is a very intuitive supervised learning algorithm and as its name suggests, it is a regression technique. This means that is is used <span class="underline"> when we have labels that are continuous values </span> such as car prices or the temperature in a room. 

Linear regression seeks to find fits of data that are lines. What does this mean?

<h3> Motivations </h3>

Imagine that you received a dataset consisting of cars, where for each car you had the number of miles a car had driven along with its price. In this case, let's assume that you are trying to train a machine learning system that takes in the information about each car, namely the number of miles driven along with its associated price. 

Here for a given car, the miles driven is the input and the price is the output. This data could be represented as $(X,Y)$ coordinates. 

It seems that there is a linear relationship between the miles driven and the price. We could describe the model for our car price dataset as a mathematical function of the form: $F(X) = A_1 \cdot X + A_0$.

Here, $A_1$ and $A_0$ are called weights and these are the values that determine how our linear function behaves on different inputs. All supervised learning algorithms have some set of weights that determine how the algorithm behaves on different inputs, and determining the right weights is really at the core of what we call <span class="blue"> learning </span>.

<h3> A Training Paradigm </h3>

How do we actually learn the weights of this model or any machine learning model in general? In particular, how can we leverage the fact that we have the correct labels for the cars in our dataset?

Training and evaluating machine learning model involves using something called a <span class="red"> cost function </span>. In the case of supervised learning, a cost function is a measure of how much the predicted labels outputted by our model deviate from the true labels. Ideally, we would like the deviation between the two to be small, and so we want to minimize the value of our cost function.

A common cost function used for evaluating linear regression models is called the <span class="blue"> least-squares cost function </span>. Let's say that we have $n$ datapoints in our dataset.

This could look like $[(X_1, Y_1), (X_2, Y_2), \dots, (X_n, Y_n)]$. If we are learning a function $F(X)$, the least-squares regression model seeks to minimize: 

$$
C(X) = \frac{1}{2} \cdot \sum_{i=1}^n (F(X_i) - Y_i)^2
$$

The deviation between our predicted output ($F(X)$) and the true output ($Y$) is defined as a residual. The least-squares cost is trying to minimize the sum of the squares of the residuals (multiplied by a constant in this case).

Here it is important to note that $F(X)$ is a function of the weights of our model. In our motivating example, $F(X)$ would be a function of $A_1$ and $A_0$. The values of $A_1$ and $A_0$ that produce our optimal model are the values which achieve the minimal value of $C(X)$. 

How do we actually compute the weights that achieve the minimal values of our cost? Here, as with all machine learning models, we have two options: an analytical or a numerical solution. 

In analytical solution, we seek to find an exact closed-form expression for the optimal value. In this particular case, that involves using standard calculus optimization. We would take the gradients (which are just fancy derivatives) of the cost function with respect to the weights, set those gradients to $0$, and then solve for the weights that achieve the $0$ gradient. 

This technique is nice because once we have computed the closed-form expression for the gradients, we can get the optimal weight values for any new data. Here we are able to develop an analytical solution in the case of linear regression with a least-squares cost function. 

However, not all models have nice well-formed gradient expressions that allow us to solve for the global optimum of a problem. For these problems, we must turn to numerical methods. Numerical methods typically involve a step-wise update procedure that iteratively brings weights closer to their optimal value. Here, we again compute the gradients with respect to all the weights and then apply the following update for each weight $A$:

$$
A_{new} = A_{old} - \alpha \cdot \frac{\partial C}{\partial A}
$$

We continue applying these updates for some number of iterations until our weight values converge, by which I mean to say they don't change too much from one iteration to the next. This very important numerical optimization procedure is called gradient descent. 


Note in our expression for gradient descent above, we have this magical alpha ($\alpha$) value being multiplied to the gradient. $\alpha$ is an example of what is called in machine learning a hyperparameter. The value of this hyperparameter $\alpha$ determines how quickly updates are made to our weights. We are free to adjust the value so that gradient descent converges more quickly.

Many machine learning algorithms have their own hyperparameters that we can adjust and fine-tune to achieve better performance in our algorithm. For some algorithms, such as in deep learning, hyperparameter tuning is a super important task that can drastically impact how good of a system we build. 

In the case of linear regression with a least-squares cost we are guaranteed that gradient descent will eventually converge to the optimal weight values. However, certain optimization problems don't have that guarantee, and the best we can hope for is that gradient descent converges to something close to the global optimum. A prominent example of models with this behavior are deep learning models, which we will discuss in greater depth later.

An important point to keep in mind is that the original linear model we we only have two weights, $A_1$ and $A_0$. But what if we really believed that car prices were a function of two features, the number of miles driven and the size of the trunk space in cubic feet?

Now if we wanted to train a linear regression model, our dataset would have to include the number of miles driven, the size of the trunk space, and the price for every car. We would also now have three weights in our linear regression model: $A_0$, $A_1$ and $A_2$.

Furthermore, our data would now exist in a 3D coordinate system, not a 2D one. However, we could use the same least-squares cost function to optimize our model. As we increase the number of features, the same basic algorithmic considerations apply with a few caveats. We will discuss these caveats when we discuss the bias-variance tradeoff.

<h3> When Does a Linear Line Fit? </h3>

When does linear regression work well as a modelling algorithm choice? In practice, it turns out that linear regression works best when there actually is a linear relationship between the inputs and the outputs of your data. 

When we are building a machine learning system, there are few factors that we have to determine. First off, we need to extract the correct features from our data. This step is crucial!

After selecting features, we need to pick the right modelling algorithm to fit. For example, if we think there is a linear relationship between our inputs and outputs, a linear regression may make sense. However, if we don't think a line makes sense, we would pick a different model that has some different assumptions about the underlying structure of the data. We will investigate many other classes of models with their assumptions about the data in later sections.

<h2> Introduction to Logistic Regression </h2>

In this section, we will continue with our study of supervised learning by exploring our first classification algorithm. A vast majority of problems tackled in the real world involve classification, so we are at an exciting milestone in our study of artificial intelligence!

Ironically, the first classification algorithm we will investigate is called logistic regression. Putting aside name confusion for now, the form of logistic regression we will look at is for binary classification tasks, where we only output two possible labels.

<h3> Model Definition </h3>

To motivate logistic regression, let us begin with a modified version of our running car example from the last section on linear regression. 

Rather than build a system to predict the price of a car, we will build a system that is provided a set of features of a car and will determine whether the car is expensive or cheap. In particular, we will extract a few different features from the cars in our dataset such as the size of the trunk, the number of miles driven, and who the car manufacturer is. 

Let's call these features $X_1$, $X_2$ and $X_3$. We will consolidate these features into a single vector variable $X = (X_1, X_2, X_3)$. These features will be fed into a mathematical function $F(X)$, to get a probability of whether or not the car is expensive. 

In other words, we will compute $F(X)$ (where the function $F$ is unspecified for now), and this will give us a probability between $0$ and $1$. We will then say that if our probability is greater than or equal to 0.5, we will label our prediction, expensive, otherwise, it will be cheap. 

Note that we could have reversed the labels and said a probability greater than 0.5 is cheap and it would not have made a difference. The only important thing is to be consistent once you've selected a labelling scheme!

What exactly is going on in that $F(X)$ function? The logistic regression model describes the relationship between our input car features and the output probabilities through a very particular mathematical formulation. Given our input features $X_1$, $X_2$, and $X_3$ the formulation is as follows:

$$
F(X) = \frac{1}{1+e^{-(A_1 \cdot X_1 + A_2 \cdot X_2 + A_3 \cdot X_3}}
$$

where here the weights of our model that we have to learn are $A_1$, $A_2$, and $A_3$. 

<h3> Training the Model </h3>

How do we train the weights of a logistic regression model? Let's assume that we have a dataset of $n$ cars with their associated true labels: $[(X_1, Y_1), (X_2, Y_2), \dots, (X_n, Y_n)]$. We won't dive into the mathematical details, but it turns out we can write an expression for the total probability of our dataset which looks as follows:

$$
\prod_{i=1}^n (F(X_i))^{Y_i} \cdot (1-F(X_i))^{1-Y_i}
$$

For our purposes, understand that our aim will be to maximize this probability. We can do this by taking the derivative with respect to our weights and setting the derivative to 0. We can then run gradient descent using our computed gradient to get our optimal weights. This is analogous to the procedure used for numerically optimizing a linear regression model in the linear regression section.

<h3> Final Thoughts </h3>

Logistic regression can also be applied to problems with more than just binary outputs for a given set of inputs. In this case, the model is called multinomial logistic regression. 

For this section, we have restricted to binary outputs because it is a natural place to start. That being said, multinomial logistic regression is especially important for more sophisticated models used in deep learning.

When is logistic regression useful? In practice, logistic regression is a very nice off-the-shelf algorithm to begin with when you are doing any type of classification. 

It has a fairly straightforward description, can be trained fairly quickly through techniques such as gradient descent because of its nice derivative, and often works well in practice. It is used frequently in biostatistical applications where there are many binary classification problem. 

<h3> Model Specification </h3>

Linear regression is a model of the form 

$$
p(y|x,\theta) = \mathcal{N}(y| w^T \phi(x), {\sigma}^2)
$$

This is known as basis function expansion. (Note that the model is still linear in the parameters $w$, so it is called linear regression; the importance of this will become clear below.) A simple example are polynomial basis functions, where the model has the form

$$
\phi(x) = [1, x, x^2, \dots, x^d]
$$

Increasing the degree $d$ allows us to create increasingly complex functions. We can also apply linear regression to more than $1$ input. For example, consider modeling temperature as a function of location. $\mathbb{E}[y|x] = w_0 + w_1 x_1 + w_2 x_2$. 

<h3> Maximum Likelihood Estimation (Least Squares) </h3>

A common way to estimate the parameters of a statistical model is to compute the MLE, which is defined as

$$
\hat{\theta} \triangleq = \argmax_{\theta} \log p(D|\theta)
$$

<h2> Why So Naive, Bayes? </h2>

I hope you're excited to learn about another fantastic class of machine learning models: Naive Bayes. Naive Bayes is wonderful because its core assumptions can be described in about a sentence, and yet it is immensely useful in many different problems.

But before we dive into the specifics of Naive Bayes, we should spend some time discussing the difference between two categories of machine learning models: discriminative and generative models. 

<h3> Beginnings </h3>

Naive Bayes will be the first generative algorithm we look at, though other common examples include hidden markov models and generative adversarial networks. 

We start from the distribution we are trying to learn $P(X_1, X_2, X_3, Y)$. We can expand the distribution using a few rules of probability along with Bayes' Rule:

$$
P(X_1, X_2, X_3, Y) = P(Y) \cdot P(X_1|Y) \cdot P(X_2|X_1,Y) \cdot P(X_3|X_1, X_2, Y)
$$

This formulation was derived from a few applications of the chain rule of probability. Now we get to the big underlying assumption of the Naive Bayes model. 

We now assume that for a given feature $X_2$, if we know the label $Y$, then knowing the value of an additional feature $X_1$ doesn't offer us any more information about $X_2$. We say that the input features are conditionally independent given the outputs. 

Mathematically, this is written as $P(X_2|X_1,Y) = P(X_2|Y). This allows us to simplify the right side of our probability expression substantially:

$$
P(X_1, X_2, X_3, Y) = P(Y) \cdot P(X_1|Y) \cdot P(X_2|Y) \cdot P(X_3|Y)
$$

An with that, we have the expression we need to train our model!

<h3> Naive Training </h3>

So, how do we actually train the model? In practice, to get the most likely label for a given input, to get the most likely label for a given input, we need to compute these values $P(X_1|Y)$, $P(X_2|Y)$ etc. Computing these values can be done through the very complicated process of counting!

Let's take a concrete example to illustrate the procedure. For our car example, let's say $Y$ represents cheap and $X_1$ represents the feature of a car's manufacturer.

Let's say we have a new car manufactured by Honda. In order to compute $P(X_1=Honda|Y=cheap)$, we simply count all the times in our dataset we had a car manufactured by Honda that was cheap. 

Assume our dataset had 10 cheap, Honda cars. We then normalize that value by the total number of cheap cars we have in our dataset. Let's say that we had 25 cheap cars in total. We thus get $P(X_1=Honda|Y=cheap)=2/5$. 

We can compute similar expressions for all the features of our new car. We then compute an aggregated probability that the car is cheap by multiplying all these individual expressions together. 


We can compute a similar expression for the probability that our car is expensive. We then assign the car the label with higher probability. That outlines how we both train our model by what are called feature-label co-occurences and then use these values to compute labels for new cars.

<h3> Final Thoughts </h3>

Naive Bayes is a super useful algorithm because its extremely strong independence assumptions make it a fairly easy model to train. Moreover, in spite of these independence assumptions, it is still extremely powerful and has been used on problems such as spam filtering in some early version email messaging clients.

However, the same reason Naive Bayes is such an easy model totrain (namely its stong independence assumptions) also makes it not a clear fit for certain other problems. If we have a strong suspicion that certain features in a problem are highly correlated, then Naive Bayes may not be a good fit. 

One example of this could be if we are using the language in an email message to label whether it has positive or negative sentiment, and we use features for whether or not a message contains certain words. 

The presence of a given swear word would be highly correlated with the appearance of any other word, but Naive Bayes would disregard this correlation by making false independence assumptions. Our model could then severely underperform because it is ignoring information about the data. This is something to be careful about when using this model!

<h2> Basics of Support Vector Machines </h2>

In this section, we will explore a family of classification algorithms that has a very different theoretical motivation from ones we've seen previously. We will be looking at support vector machines. 

Back in the early 2000s before deep learning surged to the forefront of AI, support vector machines were the cool kid on the block. Even today, support vector machines are still one of the best go-to algorithms for a new classification task because of their powerful ability to represent very diverse types of statistical relationships in data as well as their ease of training. 

<h3> Max-Margin Motivations </h3>

Let's begin by motivating support vector machines. Recall our ridiculously overused classification problem: identifying whether a car is cheap or expensive, based on a set of features of that car.

Imagine that we are plotting some of our data in 2-dimensional feature space. In other words, we are only extracting two features, $X_1$ and $X_2$, from each car for building our model. Furthermore, let's label each point BLUE if it represents a car that is cheap and RED if it represents a car that is labelled expensive. 

We will try to learn a linear model of our features, parameterized by the weights $W_1$ and $W_2$. Our model will output BLUE if $W_1 \cdot X_1 + W_2 \cdot X_2 < 0$ and RED if $W_1 \cdot X_1 + W_2 \cdot X_2 >= 0$. 

This model will describe a linear separator of a collection of data. That linear separator of our data could look as shown in Figure 11. 

Here the datapoints above the line are classified as RED, while those below are classified as BLUE. The important thing to see is that this is only one possible linear separator of the data. However, we could envision another separator that could separate the dataset into two colored halves just as well.

In fact, there are infinite number of possible separators that would split the data perfectly! How do we choose among them?

Consider how we decide to label a datapoint as RED or BLUE. We computed $W_1 \cdot X_1 + W_2 \cdot X_2$ and said if it was negative, we labelled the point BLUE. Otherwise we labelled it RED. Intuitively, it seeems that if the quantity $W_1 \cdot X_1 + W_2 \cdot X_2$ for a given point is $15$, we are more confident that it should be RED than one for which the quantity is 1. 

Alternatively, the more negative the quantity is for a point the more confident we are that it should be BLUE. In fact, we can use this value to judge our confidence for every single point!

Geometrically, this confidence for a point's label can be represented as the perpendicular distance from the point to the separator. In the figure, we have designated the perpendicular distances to the separator for several sample points with the GREEN lines.

Now imagine if we took the minimum distance to the separator across all the points in the dataset. This minimum value is called the margin. We show the point that achieves the margin for the given separator.

Optimal margins are at the core of support vector machine theory, and they inform how we will pick the best linear separator among the infinite choices. The way we will do this is by picking the linear separator that maximizes the margin. 

Put another way, each separator defines a certain margin (i.e. an associated minimum perpendicular distance to the separator). Then, among the infinite possible separators, we will pick the separator that maximizes the margin.

Make sure you really understand the last statement. Support vector machines are often called max-margin classifiers for that exact reason. Given an optimal margin linear separator, the points with the smallest margins that are closest to the linear separator are called the support vectors. 

<h3> Training the SVM </h3>

So how dow we train a support vector machine? The full mathematical details to describe the cost function we want to optimize are a bit beyond the scope of this section, but we will give a brief description of the training cost function. 

Given a collection of datapoints $[(X_1, Y_1), (X_2, Y_2), \dots, (X_n, Y_n)]$ (where $X$ are the input features and $Y$ are the correct output labels) and a vector of weights $W$ for our input features, finding the optimal margin classifier amounts to solving 

$$
\min_{w} \frac{1}{2} \lVert W \rVert^2
$$

such that

$$
Y_i (W^T X_i) \geq 1
$$ 

for all $i=1, \dots, n$. This cost function is basically a fancy way of saying that we want to maximize the margin, while ensuring the margin of each datapoint is greater than or equal to 1.

It turns out finding the optimum for this cost function si a convex optimization problem, while means there exist standard algorithms for solving the problem. This is good news for us because it means optimally training a support vector machine is a tractable problem!

As a point of comparison, there exist some problems for which we cannot find the optimal value in a computationally reasonable time. It may even take exponential time to find the optimum!

<h3> The Kernel Trick </h3>

Thus far we have motivated support vector machines by only focusing on linear separators of data. It turns out that support vector machines can actully learn nonlinear separators, which is why they are such a powerful model class!






<picture><img src="{{site.baseurl}}/assets/images/disparity.png"></picture>

<h2> References </h2>
<ul><li><a=href=""> TheAILearner </a></li>
</ul>

